import os
import requests
from datetime import datetime, timedelta

# --- 1. é±¼å¡˜é…ç½®ï¼šç²¾å‡†å®šä¹‰ä½ çš„ç›‘æ§èŒƒå›´ ---
MONITOR_TARGETS = [
    "deepseek-ai/DeepSeek-V3", "deepseek-ai/DeepSeek-Coder", # é¡¶çº§å¤§å‚
    "QwenLM/Qwen2.5", "THUDM/ChatGLM",                      # å›½äº§ä¹‹å…‰
    "vllm-project/vllm", "tgi-project/text-generation-inference", # æ¨ç†æ¡†æ¶
    "unslothai/unsloth", "meta-llama/llama3"                # è®­ç»ƒä¸å¾®è°ƒ
]

# --- 2. çŒå¤´é›·è¾¾æƒé‡é…ç½® ---
FOLLOWER_THRESHOLD = 30    # ç²‰ä¸é—¨æ§›
LOCATION_FOCUS = ["Beijing", "Shanghai", "Shenzhen", "Hangzhou", "China", "åŒ—äº¬", "ä¸Šæµ·", "æ·±åœ³", "æ­å·"]
KEY_TAGS = ["Expert", "Lead", "Staff", "Founder", "PhD", "Principal", "Researcher"]
TARGET_COMPANIES = ["Google", "Meta", "OpenAI", "Anthropic", "ByteDance", "Tencent", "Alibaba", "Baidu", "DeepSeek"]

GH_TOKEN = os.getenv("GH_TOKEN")
FEISHU_WEBHOOK = os.getenv("FEISHU_WEBHOOK")
headers = {"Authorization": f"token {GH_TOKEN}", "Accept": "application/vnd.github.v3.star+json"}

def analyze_talent(user_data):
    """äººæ‰ç”»åƒæ‰“åˆ†ä¸è¯†åˆ«é€»è¾‘"""
    bio = (user_data.get('bio') or "").lower()
    company = (user_data.get('company') or "").lower()
    loc = (user_data.get('location') or "").lower()
    followers = user_data.get('followers', 0)
    
    tags = []
    # åœ°åŒºè¯†åˆ«
    if any(city.lower() in loc for city in LOCATION_FOCUS):
        tags.append("ğŸ“ ç›®æ ‡åœ°åŒº")
    # èƒŒæ™¯è¯†åˆ«
    if any(comp.lower() in company or comp.lower() in bio for comp in TARGET_COMPANIES):
        tags.append("ğŸ¢ é¡¶å°–å¤§å‚")
    # èŒä½è¯†åˆ«
    if any(tag.lower() in bio for tag in KEY_TAGS):
        tags.append("ğŸ‘¨â€ğŸ’» èµ„æ·±/ä¸“å®¶")
    # å½±å“åŠ›è¯†åˆ«
    if followers > 200:
        tags.append("ğŸŒŸ ä¸šå†…KOL")
    elif followers > 50:
        tags.append("ğŸ“ˆ æ½œåŠ›è‚¡")

    return tags

def get_recent_stars(repo):
    url = f"https://api.github.com/repos/{repo}/stargazers"
    response = requests.get(url, headers=headers)
    if response.status_code != 200: return []

    talents = []
    one_hour_ago = datetime.utcnow() - timedelta(hours=1)
    
    for entry in response.json()[-30:]: # æ£€æŸ¥æœ€è¿‘çš„30ä¸ªç‚¹æ˜Ÿè€…
        starred_at = datetime.strptime(entry['starred_at'], '%Y-%m-%dT%H:%M:%SZ')
        if starred_at > one_hour_ago:
            u_url = entry['user']['url']
            u_data = requests.get(u_url, headers=headers).json()
            tags = analyze_talent(u_data)
            
            if tags: # åªè¦å‘½ä¸­äº†ä»»ä½•ä¸€ä¸ªæ ‡ç­¾ï¼Œå°±åˆ¤å®šä¸ºä»·å€¼äººæ‰
                talents.append({
                    "name": u_data.get('name') or u_data.get('login'),
                    "company": u_data.get('company', 'ä¸ªäººå¼€å‘è€…'),
                    "loc": u_data.get('location', 'æœªçŸ¥'),
                    "tags": " | ".join(tags),
                    "url": u_data.get('html_url')
                })
    return talents

def send_feishu_card(repo_name, talents):
    if not talents: return
    elements = [{"tag": "div", "text": {"tag": "lark_md", "content": f"âš¡ **{repo_name}** åˆšåˆšå¸å¼•äº†ä»¥ä¸‹äººæ‰ï¼š"}}]
    
    for t in talents:
        elements.append({
            "tag": "div",
            "text": {"tag": "lark_md", "content": f"**[{t['name']}]({t['url']})**\n{t['tags']}\nğŸ¢ {t['company']} Â· ğŸ“ {t['loc']}"}
        })
    
    card = {
        "msg_type": "interactive",
        "card": {
            "header": {"title": {"tag": "plain_text", "content": "ğŸ¯ é¡¶çº§ AI çŒå¤´ä¼ æ„Ÿå™¨"}, "template": "orange"},
            "elements": elements
        }
    }
    requests.post(FEISHU_WEBHOOK, json=card)

if __name__ == "__main__":
    for repo in MONITOR_TARGETS:
        found = get_recent_stars(repo)
        if found: send_feishu_card(repo, found)
